{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJs-vYywvB6R"
      },
      "outputs": [],
      "source": [
        "# Install OpenAI Whisper and FFmpeg\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!sudo apt update && sudo apt install ffmpeg -q\n",
        "\n",
        "import whisper\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kpYvcvuvO3L",
        "outputId": "8f90539c-06b1-4a09-a340-6279900b272b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper # Added this import statement\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/...\"\n",
        "\n",
        "# Model size: 'base', 'small', 'medium', 'large'\n",
        "# 'medium' is a good balance of speed and accuracy for long files on Colab free tier.\n",
        "# Use 'large' for maximum accuracy (might be slower).\n",
        "model_size = \"large\"\n",
        "# ---------------------\n",
        "\n",
        "# Check if file exists\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "else:\n",
        "    print(f\"Loading Whisper model '{model_size}'...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    print(f\"Transcribing {file_path}...\")\n",
        "    print(\"This may take a while for a 2-hour file. Please wait...\")\n",
        "\n",
        "    # The actual transcription process\n",
        "    # verbose=False keeps the output clean, set to True if you want to see live progress\n",
        "    result = model.transcribe(file_path, verbose=False)\n",
        "\n",
        "    # Prepare output filenames\n",
        "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "    output_folder = os.path.dirname(file_path)\n",
        "    txt_path = os.path.join(output_folder, f\"{file_name}_transcript.txt\")\n",
        "\n",
        "    # Save to text file\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result[\"text\"])\n",
        "\n",
        "    print(\"--- SUCCESS ---\")\n",
        "    print(f\"Transcription saved to: {txt_path}\")\n",
        "\n",
        "    # Optional: Print the first 500 characters to verify\n",
        "    print(\"\\nPreview:\")\n",
        "    print(result[\"text\"][:500] + \"...\")"
      ],
      "metadata": {
        "id": "kNnRlbI0vQvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from whisper.utils import get_writer\n",
        "\n",
        "# Save as SRT (Subtitle format with timestamps)\n",
        "srt_writer = get_writer(\"srt\", output_folder)\n",
        "srt_writer(result, file_name)\n",
        "print(f\"Saved SRT file to {output_folder}\")"
      ],
      "metadata": {
        "id": "Fib8f3KkvWkI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}